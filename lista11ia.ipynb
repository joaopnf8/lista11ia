{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Pipeline de IA com a Base de Dados do Titanic", "Lista 11 - Intelig\u00eancia Artificial"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Importa\u00e7\u00e3o de Bibliotecas e Carregamento da Base"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd", "import numpy as np", "import seaborn as sns", "import matplotlib.pyplot as plt", "from sklearn.model_selection import train_test_split", "from sklearn.preprocessing import StandardScaler, LabelEncoder", "from sklearn.ensemble import RandomForestClassifier", "from sklearn.tree import DecisionTreeClassifier", "from sklearn.metrics import classification_report, confusion_matrix", "from sklearn.decomposition import PCA", "from sklearn.cluster import KMeans", "from mlxtend.frequent_patterns import apriori, association_rules", "", "# Carregando os dados", "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. An\u00e1lise Explorat\u00f3ria e Pr\u00e9-Processamento"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verificando informa\u00e7\u00f5es gerais", "df.info()", "", "# Estat\u00edsticas descritivas", "df.describe()", "", "# Valores nulos", "df.isnull().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Preenchendo valores nulos", "df['Age'].fillna(df['Age'].median(), inplace=True)", "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)", "df.drop(columns=['Cabin'], inplace=True)  # Muitas informa\u00e7\u00f5es faltantes", "", "# Extraindo t\u00edtulo dos nomes", "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)", "df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')", "df['Title'] = df['Title'].replace(['Mme', 'Lady', 'Countess', 'Dona'], 'Mrs')", "df['Title'] = df['Title'].replace(['Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer'], 'Rare')", "", "# Criando vari\u00e1vel \"FamilySize\"", "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1", "", "# Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas", "df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Title'], drop_first=True)", "", "# Removendo colunas irrelevantes", "df.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)", "", "# Separando vari\u00e1veis", "X = df.drop('Survived', axis=1)", "y = df['Survived']", "", "# Normalizando vari\u00e1veis num\u00e9ricas", "scaler = StandardScaler()", "X_scaled = scaler.fit_transform(X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Modelagem Supervisionada (Classifica\u00e7\u00e3o)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Dividindo os dados", "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)", "", "# Random Forest", "rf = RandomForestClassifier()", "rf.fit(X_train, y_train)", "y_pred_rf = rf.predict(X_test)", "", "# Decision Tree", "dt = DecisionTreeClassifier()", "dt.fit(X_train, y_train)", "y_pred_dt = dt.predict(X_test)", "", "# Avalia\u00e7\u00e3o", "print(\"Random Forest:", "\", classification_report(y_test, y_pred_rf))", "print(\"Decision Tree:", "\", classification_report(y_test, y_pred_dt))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Modelagem N\u00e3o Supervisionada (Clusteriza\u00e7\u00e3o)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Aplicando PCA para visualiza\u00e7\u00e3o", "pca = PCA(n_components=2)", "X_pca = pca.fit_transform(X_scaled)", "", "# KMeans", "kmeans = KMeans(n_clusters=2, random_state=42)", "clusters = kmeans.fit_predict(X_scaled)", "", "# Visualizando", "plt.figure(figsize=(10,6))", "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters, palette='viridis')", "plt.title(\"Clusters de Passageiros (K-Means + PCA)\")", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Regras de Associa\u00e7\u00e3o"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Selecionando colunas categ\u00f3ricas binarizadas", "assoc_df = df.copy()", "assoc_df['Survived'] = assoc_df['Survived'].astype(bool)", "", "# Binarizando as vari\u00e1veis para Apriori", "assoc_df_bin = assoc_df.copy()", "assoc_df_bin = assoc_df_bin.astype(int).astype(bool)", "", "# Aplicando Apriori", "frequent_itemsets = apriori(assoc_df_bin, min_support=0.1, use_colnames=True)", "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)", "", "# Exibindo 3 regras com maior lift", "rules.sort_values(by=\"lift\", ascending=False).head(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Conclus\u00e3o"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Com base na an\u00e1lise, os principais insights foram:", "", "- O modelo Random Forest teve melhor desempenho que a \u00e1rvore de decis\u00e3o.", "- A vari\u00e1vel 'Title' e o tamanho da fam\u00edlia foram relevantes na predi\u00e7\u00e3o de sobreviv\u00eancia.", "- A clusteriza\u00e7\u00e3o revelou agrupamentos distintos com base no perfil dos passageiros.", "- As regras de associa\u00e7\u00e3o indicam padr\u00f5es importantes, como alta sobreviv\u00eancia de mulheres de 1\u00aa classe.", "", "O pipeline apresentado demonstra como aplicar t\u00e9cnicas supervisionadas, n\u00e3o supervisionadas e de associa\u00e7\u00e3o em dados reais."]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}